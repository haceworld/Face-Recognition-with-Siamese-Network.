{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program is just implemented as a help file to calculate encodings and \n",
    "# apply TSNE algorithm to see if anchor images could have been distinguished \n",
    "# from each other by the model after the training.\n",
    "\n",
    "# The file:\n",
    "# 1) re-loads the pretrained model (the one to be used in prediction)\n",
    "# 2) For each anchor image, the face encoding is calculated and saved ina python dictionary.\n",
    "#    This dictionary is saved in a file so that we can skip re-calculating face encodings of anchor images\n",
    "#    each time we want to make a prediction later on. Face encodings can just be read from the .dat file\n",
    "#    where we save anchor image paths and anchor image face encodings.\n",
    "# 3) TSNE is applied to 128 dimensional face encodings of anchor images to reduce the number of dimensions\n",
    "#    down to 3 and we save results of TSNE to a csv file to be able to have a closer look later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesncn/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "#import PIL\n",
    "#from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, subtract, concatenate, Lambda, add, maximum\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model, model_from_json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoding_network to make predictions based on trained network\n",
    "\n",
    "json_file = open('/home/cesncn/Desktop/github_projects/face_recognition/code/saved_model/encoding_network_arch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_network = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "encoding_network.load_weights('saved_model/encoding_network_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(8, 1, 128)\n",
      "(8, 128)\n",
      "(8, 2)\n"
     ]
    }
   ],
   "source": [
    "# 1) Put each anchor_img_path and anchor_encoding to a dictionary and later save all these pairs\n",
    "#    in a new file that will later be used when making predictions.\n",
    "# 2) Create the array of encodings that will be input to TSNE. And run TSNE.\n",
    "\n",
    "# Note that pd.read_csv function assumes that the first row is header and skips this row when reading..\n",
    "reader = pd.read_csv('../dataset/train/anchor_img_paths.csv', chunksize=1)\n",
    "\n",
    "encodings_list = []\n",
    "encodings_dict = {}\n",
    "\n",
    "for chunk in reader:\n",
    "    encoding_net_anchor_inputs = np.empty((0, 224, 224, 3))\n",
    "    anchor_img = image.load_img(chunk.iloc[0, 0], target_size=(224, 224))  # chunk.iloc[0, 0] is the img_path\n",
    "    anchor_img = image.img_to_array(anchor_img)\n",
    "    anchor_img = np.expand_dims(anchor_img, axis=0)\n",
    "    anchor_img = preprocess_input(anchor_img)\n",
    "    encoding_net_anchor_inputs = np.append(encoding_net_anchor_inputs, anchor_img, axis=0)\n",
    "    anchor_encoding = encoding_network.predict([encoding_net_anchor_inputs], \n",
    "                                               batch_size = 1, \n",
    "                                               verbose = 0)   \n",
    "    \n",
    "    # save anchor encoding in a file to later use in predictions\n",
    "    encodings_dict[chunk.iloc[0, 0]] = anchor_encoding   # chunk.iloc[0, 0] is the img_path\n",
    "    \n",
    "    print(anchor_encoding.shape)\n",
    "    encodings_list.append(anchor_encoding)\n",
    "\n",
    "with open('anchor_encodings_dict.dat', 'wb') as f:\n",
    "    pickle.dump(encodings_dict, f)\n",
    "\n",
    "encodings_array = np.array(encodings_list)\n",
    "print(encodings_array.shape)\n",
    "reshaped_encodings_array = np.reshape(encodings_array, \n",
    "                                      (encodings_array.shape[0], encodings_array.shape[2]))\n",
    "print(reshaped_encodings_array.shape)\n",
    "encodings_embedded = TSNE(n_components=2, perplexity=10).fit_transform(reshaped_encodings_array)\n",
    "print(encodings_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just write the results from TSNE into a CSV file\n",
    "\n",
    "reader = pd.read_csv('../dataset/train/anchor_img_paths.csv', chunksize=1)\n",
    "i = 0\n",
    "write_header = True  # Needed to get header for first chunk\n",
    "for chunk in reader:\n",
    "    chunk['tsne_dim_1'] = encodings_embedded[i, 0]\n",
    "    chunk['tsne_dim_2'] = encodings_embedded[i, 1]\n",
    "    i += 1\n",
    "    chunk.to_csv('anchor_img_tsne.csv', mode='a', header=write_header, index=False)\n",
    "    write_header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
