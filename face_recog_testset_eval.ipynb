{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program re-loads the pretrained model, calculates face encodings for each test image,\n",
    "# calculates distances between encodings of test and anchor images (for accuracy check)\n",
    "# To have a better view on results, the distance between each test image and each anchor image is\n",
    "# calculated separately and saved in a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesncn/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "#import PIL\n",
    "#from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, subtract, concatenate, Lambda, add, maximum\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model, model_from_json\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoding_network to make predictions based on trained network\n",
    "\n",
    "json_file = open('/home/cesncn/Desktop/github_projects/face_recognition/code/saved_model/encoding_network_arch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_network = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "encoding_network.load_weights('saved_model/encoding_network_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each test image, the distance with each anchor image has been calculated and saved in the file test_set_prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Calculate the 128 dimensional face encoding for each test image and calculate the distance \n",
    "#    with all anchor images.\n",
    "# 2) Save results in a csv file.\n",
    "\n",
    "# Note that pd.read_csv function assumes that the first row is header and skips this row when reading..\n",
    "reader = pd.read_csv('../dataset/test/test1.csv', chunksize=1)\n",
    "\n",
    "# Load face encodings\n",
    "with open('anchor_encodings_dict.dat', 'rb') as f:\n",
    "    all_face_encodings = pickle.load(f)\n",
    "    \n",
    "write_header = True\n",
    "\n",
    "for chunk in reader:\n",
    "    encoding_net_test_inputs = np.empty((0, 224, 224, 3))\n",
    "    test_img = image.load_img(chunk.iloc[0, 1], target_size=(224, 224))\n",
    "    test_img = image.img_to_array(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    test_img = preprocess_input(test_img)\n",
    "    encoding_net_test_inputs = np.append(encoding_net_test_inputs, test_img, axis=0)\n",
    "    test_encoding = encoding_network.predict([encoding_net_test_inputs], \n",
    "                                             batch_size = 1, \n",
    "                                             verbose = 0)      \n",
    "    \n",
    "    for (anchor_img_path, anchor_encoding) in all_face_encodings.items():\n",
    "        distance = np.linalg.norm(anchor_encoding - test_encoding)\n",
    "        chunk[anchor_img_path[-6:]] = distance  # only write the last 6 letters of each anchor path in the first row\n",
    "    \n",
    "    chunk.to_csv('test_set_prediction_results.csv', mode='a', header=write_header, index=False)\n",
    "    write_header = False  # Update so later chunks don't write header\n",
    "\n",
    "print(\"For each test image, the distance with each anchor image has been calculated and saved\",\n",
    "      \"in the file test_set_prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
