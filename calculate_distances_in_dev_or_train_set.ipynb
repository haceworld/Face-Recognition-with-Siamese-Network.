{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file calculates positive and negative distances for the triplets in train and dev sets.\n",
    "# This is just done for the evaluation purpose to see how distances look like after training the model.\n",
    "\n",
    "# Depending on whether distances are calculated for triplets in DEV or TRAIN set, 2 lines below need \n",
    "# to be uncommented to read triplets from the right file and write results to the right file.\n",
    "# Search for \"UN-COMMENT\" below to see what to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesncn/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "#import PIL\n",
    "#from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, subtract, concatenate, Lambda, add, maximum\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model, model_from_json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoding_network to make predictions based on trained network\n",
    "\n",
    "json_file = open('/home/cesncn/Desktop/github_projects/face_recognition/code/saved_model/encoding_network_arch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_network = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "encoding_network.load_weights('saved_model/encoding_network_weights.h5')\n",
    "#weights = siamese_network.get_layer('model_1').get_weights()\n",
    "#encoding_network.get_layer('model_1').set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for debugging\n",
    "#print(\"bn3d_branch2c: (Should be same)\\n\", \n",
    "#      siamese_network.get_layer('model_1').get_layer('bn3d_branch2c').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for debugging\n",
    "#print(\"bn3d_branch2c: (Should be same)\\n\", \n",
    "#      encoding_network.get_layer('model_1').get_layer('bn3d_branch2c').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for debugging\n",
    "#print(\"res2a_branch2a: \\n\", \n",
    "#      encoding_network.get_layer('model_1').get_layer('res2a_branch2a').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for debugging\n",
    "#print(\"model_out: \\n\", \n",
    "#      encoding_network.get_layer('model_1').get_layer('model_out').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3589267\n",
      "1.4142135\n",
      "0.96131736\n",
      "1.4142135\n",
      "1.4142135\n",
      "1.395996\n",
      "1.3164446\n",
      "1.3319315\n",
      "1.3589267\n",
      "1.0061738\n",
      "0.96131736\n",
      "1.337185\n",
      "1.4142135\n",
      "1.2720106\n",
      "1.3164446\n",
      "1.4142135\n",
      "1.3589267\n",
      "1.4054251\n",
      "0.96131736\n",
      "1.3791401\n",
      "1.4142135\n",
      "1.4142137\n",
      "1.3164446\n",
      "1.2993113\n",
      "0.3205826\n",
      "1.4033155\n",
      "0.21892601\n",
      "1.4142135\n",
      "0.28243002\n",
      "1.4142135\n",
      "0.37172902\n",
      "1.4142135\n",
      "0.3205826\n",
      "1.4115312\n",
      "0.21892601\n",
      "1.4142135\n",
      "0.28243002\n",
      "1.4142135\n",
      "0.37172902\n",
      "1.3865782\n",
      "0.3205826\n",
      "1.4142135\n",
      "0.21892601\n",
      "1.3720733\n",
      "0.28243002\n",
      "1.2385437\n",
      "0.37172902\n",
      "1.3069544\n",
      "0.43403572\n",
      "1.4142135\n",
      "0.5520116\n",
      "1.4142135\n",
      "0.6311723\n",
      "1.1384537\n",
      "0.6277568\n",
      "1.0760819\n",
      "0.43403572\n",
      "1.4008762\n",
      "0.5520116\n",
      "1.1267905\n",
      "0.6311723\n",
      "1.3926901\n",
      "0.6277568\n",
      "1.4142135\n",
      "0.43403572\n",
      "1.3334781\n",
      "0.5520116\n",
      "1.3913288\n",
      "0.6311723\n",
      "1.4142137\n",
      "0.6277568\n",
      "1.3987681\n",
      "1.2931198\n",
      "1.4142135\n",
      "0.34815735\n",
      "1.3432546\n",
      "0.8276411\n",
      "1.1743416\n",
      "0.83620936\n",
      "1.315703\n",
      "1.2931198\n",
      "1.4142135\n",
      "0.34815735\n",
      "1.4142135\n",
      "0.8276411\n",
      "1.4142135\n",
      "0.83620936\n",
      "1.4142134\n",
      "1.2931198\n",
      "1.4142135\n",
      "0.34815735\n",
      "1.4142135\n",
      "0.8276411\n",
      "1.3813088\n",
      "0.83620936\n",
      "1.4131033\n",
      "0.8844322\n",
      "1.4142137\n",
      "0.5746296\n",
      "1.4142137\n",
      "1.0161802\n",
      "1.4022384\n",
      "0.8844322\n",
      "1.4142137\n",
      "0.5746296\n",
      "1.4142138\n",
      "1.0161802\n",
      "1.4142135\n",
      "0.8844322\n",
      "0.8844322\n",
      "0.5746296\n",
      "0.5746296\n",
      "1.0161802\n",
      "0.96659046\n",
      "0.80138314\n",
      "1.2889016\n",
      "0.68849695\n",
      "0.97430706\n",
      "0.59972984\n",
      "1.3115118\n",
      "0.80138314\n",
      "1.4142134\n",
      "0.68849695\n",
      "1.403989\n",
      "0.59972984\n",
      "1.3793299\n",
      "0.80138314\n",
      "1.3873086\n",
      "0.68849695\n",
      "1.3773843\n",
      "0.59972984\n",
      "1.4013861\n",
      "0.5401002\n",
      "1.3489398\n",
      "0.77838475\n",
      "1.4013969\n",
      "0.72721803\n",
      "1.2962774\n",
      "0.5657968\n",
      "1.4109699\n",
      "0.5401002\n",
      "1.4102954\n",
      "0.77838475\n",
      "1.3563238\n",
      "0.72721803\n",
      "1.3890111\n",
      "0.5657968\n",
      "1.3193413\n",
      "0.5401002\n",
      "1.2801139\n",
      "0.77838475\n",
      "1.3404922\n",
      "0.72721803\n",
      "1.3115468\n",
      "0.5657968\n",
      "1.4102954\n",
      "0.17321685\n",
      "1.4067894\n",
      "0.17384948\n",
      "1.3933905\n",
      "0.17321685\n",
      "1.3917773\n",
      "0.17384948\n",
      "1.4028505\n",
      "0.17321685\n",
      "1.4142135\n",
      "0.17384948\n",
      "1.347923\n"
     ]
    }
   ],
   "source": [
    "# UN-COMMENT THE LINE DEPENDING ON FOR WHICH DATA SET (TRAIN OR DEV) DISTANCES WILL BE CALCULATED\n",
    "# Read one line at at time. Change chunksize to process more lines at a time. \n",
    "# Note that pd.read_csv function assumes that the first row is header and skips this row when reading..\n",
    "#reader = pd.read_csv('../dataset/train/train1.csv', chunksize=1)\n",
    "reader = pd.read_csv('../dataset/dev/dev1.csv', chunksize=1)\n",
    "write_header = True  # Needed to get header for first chunk\n",
    "\n",
    "for chunk in reader:\n",
    "    encoding_net_anchor_inputs = np.empty((0, 224, 224, 3))\n",
    "    anchor_img = image.load_img(chunk.iloc[0, 1], target_size=(224, 224))\n",
    "    anchor_img = image.img_to_array(anchor_img)\n",
    "    #print(anchor_imgs.shape)\n",
    "    anchor_img = np.expand_dims(anchor_img, axis=0)\n",
    "    #print(anchor_imgs.shape)\n",
    "    anchor_img = preprocess_input(anchor_img)\n",
    "    encoding_net_anchor_inputs = np.append(encoding_net_anchor_inputs, anchor_img, axis=0)\n",
    "\n",
    "    anchor_encoding = encoding_network.predict([encoding_net_anchor_inputs], \n",
    "                                               batch_size = 1, \n",
    "                                               verbose = 0)   \n",
    "\n",
    "    encoding_net_pos_inputs = np.empty((0, 224, 224, 3))\n",
    "    pos_img = image.load_img(chunk.iloc[0, 2], target_size=(224, 224))\n",
    "    pos_img = image.img_to_array(pos_img)\n",
    "    pos_img = np.expand_dims(pos_img, axis=0)\n",
    "    pos_img = preprocess_input(pos_img)\n",
    "    encoding_net_pos_inputs = np.append(encoding_net_pos_inputs, pos_img, axis=0)\n",
    "\n",
    "\n",
    "    pos_encoding = encoding_network.predict([encoding_net_pos_inputs], \n",
    "                                            batch_size = 1, \n",
    "                                            verbose = 0)\n",
    "\n",
    "    encoding_net_neg_inputs = np.empty((0, 224, 224, 3))\n",
    "    neg_img = image.load_img(chunk.iloc[0, 3], target_size=(224, 224))\n",
    "    neg_img = image.img_to_array(neg_img)\n",
    "    neg_img = np.expand_dims(neg_img, axis=0)\n",
    "    neg_img = preprocess_input(neg_img)\n",
    "    encoding_net_neg_inputs = np.append(encoding_net_neg_inputs, neg_img, axis=0)\n",
    "\n",
    "\n",
    "    neg_encoding = encoding_network.predict([encoding_net_neg_inputs], \n",
    "                                            batch_size = 1, \n",
    "                                            verbose = 0)\n",
    "\n",
    "    #positive_distance, negative_distance = calc_distances([anchor_encoding, pos_encoding, neg_encoding])\n",
    "    #print(anchor_encoding)\n",
    "    #print(pos_encoding)\n",
    "    positive_distance = np.linalg.norm(anchor_encoding - pos_encoding)\n",
    "    negative_distance = np.linalg.norm(anchor_encoding - neg_encoding)\n",
    "    print(positive_distance)\n",
    "    print(negative_distance)\n",
    "    chunk['pos_dist'] = positive_distance\n",
    "    chunk['neg_dist'] = negative_distance\n",
    "\n",
    "    # UN-COMMENT THE LINE DEPENDING ON FOR WHICH DATA SET (TRAIN OR DEV) DISTANCES WILL BE CALCULATED\n",
    "    # Save the file to a csv, appending each new chunk you process. mode='a' means append.\n",
    "    #chunk.to_csv('train1_distances.csv', mode='a', header=write_header, index=False)\n",
    "    chunk.to_csv('dev1_distances.csv', mode='a', header=write_header, index=False)\n",
    "    write_header = False  # Update so later chunks don't write header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
