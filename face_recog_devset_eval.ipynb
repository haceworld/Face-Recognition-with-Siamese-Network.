{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Network with Triplet Loss Function for Face Recognition\n",
    "\n",
    "# This program re-loads the trained Siamese Network model and performs evaluation on the dev set.\n",
    "# The dev set - just like train set - consists of triplets. The aim is to check the loss on dev set by\n",
    "# providing (new) triplets to the trained model to check how loss (cost) figures are changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model, model_from_json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used when compiling the siamese network\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)  # This is actually just returning y_pred bcs\n",
    "                                        # K.mean has already been called in the triplet_loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Siamese Network for evaluation\n",
    "\n",
    "json_file = open('/home/cesncn/Desktop/github_projects/face_recognition/code/saved_model/siamese_network_arch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "siamese_network = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "siamese_network.load_weights('/home/cesncn/Desktop/github_projects/face_recognition/code/saved_model/siamese_model_weights.h5')\n",
    "\n",
    "# Since we (saved and) load the model in 2 steps (first the model architecture and then the weights), \n",
    "# we thereby need to compile the model once again so that it knows its loss function to be\n",
    "# able to evaluate the model. If we had saved the model in 1 step (with save_model) and load\n",
    "# it again in 1 step (with load_model), we would not need to compile it again bcz the load_model() \n",
    "# function calls the compile() function by default\n",
    "siamese_network.compile(optimizer=Adam(lr=.00004, clipnorm=1.), loss=identity_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"bn3d_branch2c: (Should be same)\\n\", \n",
    "#      siamese_network.get_layer('model_1').get_layer('bn3d_branch2c').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path1 = '/home/cesncn/Desktop/github_projects/face_recognition/dataset/dev/dev1.csv'\n",
    "DEV_INPUT_PATHS = [dev_path1]\n",
    "\n",
    "RECORD_DEFAULTS_DEV = [[0], [''], [''], ['']]\n",
    "\n",
    "def decode_csv_dev(line):\n",
    "   parsed_line = tf.decode_csv(line, RECORD_DEFAULTS_DEV)\n",
    "   anchor_path = parsed_line[1]\n",
    "   pos_path  = parsed_line[2]\n",
    "   neg_path    = parsed_line[3]\n",
    "   return anchor_path, pos_path, neg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 31s 1s/step\n",
      "batch number:  1 Evaluate Score (Loss):  1.3444675207138062\n",
      "Dev Set Evaluate Score (Loss):  1.3444675207138062\n",
      "21/21 [==============================] - 33s 2s/step\n",
      "batch number:  2 Evaluate Score (Loss):  1.354506492614746\n",
      "Dev Set Evaluate Score (Loss):  1.3494870066642761\n",
      "21/21 [==============================] - 31s 1s/step\n",
      "batch number:  3 Evaluate Score (Loss):  1.3082085847854614\n",
      "Dev Set Evaluate Score (Loss):  1.3357275327046711\n",
      "21/21 [==============================] - 34s 2s/step\n",
      "batch number:  4 Evaluate Score (Loss):  1.3906368017196655\n",
      "Dev Set Evaluate Score (Loss):  1.3494548499584198\n",
      "Out of range error triggered (looped through training set)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 21\n",
    "\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv_dev))\n",
    "dataset = dataset.shuffle(buffer_size=100000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "dev_eval_score = 0\n",
    "nr_dev_examples = 0\n",
    "batch_number = 0\n",
    "\n",
    "# retrieve the default tensorflow session from Keras. Needed so that the \n",
    "# code below otherwise ends up in a different session\n",
    "sess = K.get_session() \n",
    "sess.run(iterator.initializer, feed_dict={filenames: DEV_INPUT_PATHS})\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "      anchor_path, pos_path, neg_path = sess.run(next_element)\n",
    "\n",
    "      anchor_imgs = np.empty((0, 224, 224, 3))\n",
    "      pos_imgs = np.empty((0, 224, 224, 3))\n",
    "      neg_imgs = np.empty((0, 224, 224, 3))\n",
    "      for j in range (0, len(anchor_path)):\n",
    "          #print(anchor_path)\n",
    "          anchor_img = image.load_img(anchor_path[j], target_size=(224, 224))\n",
    "          anchor_img = image.img_to_array(anchor_img)\n",
    "          #print(anchor_imgs.shape)\n",
    "          anchor_img = np.expand_dims(anchor_img, axis=0)\n",
    "          #print(anchor_imgs.shape)\n",
    "          anchor_img = preprocess_input(anchor_img)\n",
    "          anchor_imgs = np.append(anchor_imgs, anchor_img, axis=0)\n",
    "          #print(anchor_img.shape)\n",
    "\n",
    "          #print(test_path)\n",
    "          pos_img = image.load_img(pos_path[j], target_size=(224, 224))\n",
    "          pos_img = image.img_to_array(pos_img)\n",
    "          pos_img = np.expand_dims(pos_img, axis=0)\n",
    "          pos_img = preprocess_input(pos_img)\n",
    "          pos_imgs = np.append(pos_imgs, pos_img, axis=0)\n",
    "          #print(pos_img.shape)\n",
    "\n",
    "          neg_img = image.load_img(neg_path[j], target_size=(224, 224))\n",
    "          neg_img = image.img_to_array(neg_img)\n",
    "          neg_img = np.expand_dims(neg_img, axis=0)\n",
    "          neg_img = preprocess_input(neg_img)\n",
    "          neg_imgs = np.append(neg_imgs, neg_img, axis=0)\n",
    "          #print(neg_img.shape)\n",
    "\n",
    "      #print(\"len(anchor_imgs): \", len(anchor_imgs))\n",
    "      #print(\"pos_imgs[0].shape: \", pos_imgs[0].shape)\n",
    "      #print(\"neg_imgs.shape: \", neg_imgs.shape)\n",
    "\n",
    "      #print(labels)\n",
    "      batch_number += 1\n",
    "\n",
    "      # dummy output, needed for being able to run the fit(..) function\n",
    "      z = np.zeros(len(anchor_path))\n",
    "\n",
    "      eval_score = siamese_network.evaluate(x=[anchor_imgs, pos_imgs, neg_imgs], \n",
    "                                            y=z,\n",
    "                                            batch_size = batch_size, \n",
    "                                            verbose = 1)\n",
    "\n",
    "      print(\"batch number: \", batch_number, \"Evaluate Score (Loss): \", eval_score)\n",
    "      dev_eval_score += (eval_score * len(anchor_imgs))\n",
    "      nr_dev_examples += len(anchor_imgs)\n",
    "      print(\"Dev Set Evaluate Score (Loss): \", dev_eval_score/nr_dev_examples)\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"Out of range error triggered (looped through training set)\")\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
